{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded and saved as face_recognition_sface_2021dec.onnx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/opencv/opencv_zoo/blob/main/models/face_recognition_sface/face_recognition_sface_2021dec.onnx?raw=true'\n",
    "local_path = 'face_recognition_sface_2021dec.onnx'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(local_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(f'Model downloaded and saved as {local_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/dnn/src/onnx/onnx_importer.cpp:277: error: (-5:Bad argument) Can't read ONNX file: face_detection_yunet_2023mar.onnx in function 'ONNXImporter'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m         cv\u001b[38;5;241m.\u001b[39mcircle(\u001b[38;5;28minput\u001b[39m, (coords[\u001b[38;5;241m12\u001b[39m], coords[\u001b[38;5;241m13\u001b[39m]), \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# Draw a circle on the fifth key point (e.g., right mouth corner)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize the face detector with a pre-trained model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFaceDetectorYN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface_detection_yunet_2023mar.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize the face recognizer with a pre-trained model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mFaceRecognizerSF\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_recognition_sface_2021dec.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/dnn/src/onnx/onnx_importer.cpp:277: error: (-5:Bad argument) Can't read ONNX file: face_detection_yunet_2023mar.onnx in function 'ONNXImporter'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv  # Import OpenCV library for computer vision tasks\n",
    "import numpy as np  # Import NumPy library for numerical operations\n",
    "\n",
    "def visualize(input, faces, thickness=2):\n",
    "    # Function to visualize detected faces and key points on an image\n",
    "    if faces[1] is not None:\n",
    "        # Check if any faces are detected\n",
    "        coords = faces[1][0].astype(np.int32)\n",
    "        # Get the coordinates of the first detected face and convert to integer\n",
    "        cv.rectangle(input, (coords[0], coords[1]), (coords[0] + coords[2], coords[1] + coords[3]), (0, 255, 0), thickness)\n",
    "        # Draw a rectangle around the face\n",
    "        cv.circle(input, (coords[4], coords[5]), 2, (255, 0, 0), thickness)\n",
    "        # Draw a circle on the first key point (e.g., left eye)\n",
    "        cv.circle(input, (coords[6], coords[7]), 2, (0, 0, 255), thickness)\n",
    "        # Draw a circle on the second key point (e.g., right eye)\n",
    "        cv.circle(input, (coords[8], coords[9]), 2, (0, 255, 0), thickness)\n",
    "        # Draw a circle on the third key point (e.g., nose)\n",
    "        cv.circle(input, (coords[10], coords[11]), 2, (255, 0, 255), thickness)\n",
    "        # Draw a circle on the fourth key point (e.g., left mouth corner)\n",
    "        cv.circle(input, (coords[12], coords[13]), 2, (0, 255, 255), thickness)\n",
    "        # Draw a circle on the fifth key point (e.g., right mouth corner)\n",
    "\n",
    "# Initialize the face detector with a pre-trained model\n",
    "detector = cv.FaceDetectorYN.create(\"face_detection_yunet_2023mar.onnx\", \"\", (320, 320), 0.8, 0.3, 5000)\n",
    "\n",
    "# Initialize the face recognizer with a pre-trained model\n",
    "recognizer = cv.FaceRecognizerSF.create(\"face_recognition_sface_2021dec.onnx\", \"\")\n",
    "\n",
    "# Load the input image from a file\n",
    "input_image = cv.imread('image path ...') # put the image of the person whose model showld know here\n",
    "input_image_copy = input_image.copy()  # Create a copy of the input image\n",
    "height, width, _ = input_image.shape  # Get the dimensions of the input image\n",
    "\n",
    "# Set the input size for the face detector\n",
    "detector.setInputSize((width, height))\n",
    "\n",
    "# Detect faces in the input image\n",
    "face1 = detector.detect(input_image)\n",
    "\n",
    "# Visualize the detected face on the copied image\n",
    "visualize(input_image_copy, face1)\n",
    "\n",
    "# Ensure that at least one face is detected\n",
    "assert face1[1] is not None, 'cannot find even an image'\n",
    "\n",
    "# Align and crop the detected face for feature extraction\n",
    "face1_crop = recognizer.alignCrop(input_image, face1[1][0])\n",
    "\n",
    "# Extract features from the cropped face\n",
    "face1_feature = recognizer.feature(face1_crop)\n",
    "\n",
    "# Open a connection to the webcam\n",
    "webcam = cv.VideoCapture(0)\n",
    "\n",
    "# Start an infinite loop to process frames from the webcam\n",
    "while True:\n",
    "    ok, frame = webcam.read()  # Read a frame from the webcam\n",
    "    if not ok:\n",
    "        break  # Exit the loop if the frame is not read correctly\n",
    "    frame = cv.flip(frame, 1)  # Flip the frame horizontally\n",
    "    frame_copy = frame.copy()  # Create a copy of the frame\n",
    "    frame_width, frame_height = int(webcam.get(cv.CAP_PROP_FRAME_WIDTH)), int(webcam.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    # Get the width and height of the frame\n",
    "    detector.setInputSize((frame_width, frame_height))\n",
    "    # Set the input size for the face detector\n",
    "\n",
    "    # Detect faces in the current frame\n",
    "    face_frame = detector.detect(frame)\n",
    "    color = (255, 0, 0)  # Set the initial color for drawing\n",
    "    message = 'cannot find even a face'  # Set the initial message\n",
    "\n",
    "    if face_frame[1] is not None:\n",
    "        # Check if any faces are detected\n",
    "        for face in face_frame[1]:\n",
    "            visualize(frame_copy, (None, [face]))\n",
    "            # Visualize the detected face on the copied frame\n",
    "\n",
    "            # Align and crop the detected face for feature extraction\n",
    "            face_frame_crop = recognizer.alignCrop(frame, face)\n",
    "\n",
    "            # Extract features from the cropped face\n",
    "            face_frame_feature = recognizer.feature(face_frame_crop)\n",
    "\n",
    "            # Set the threshold for cosine similarity\n",
    "            cosine_similarity_threshold = 0.363\n",
    "\n",
    "            # Calculate the cosine similarity score between the reference and detected face\n",
    "            cosine_score = recognizer.match(face1_feature, face_frame_feature, cv.FaceRecognizerSF_FR_COSINE)\n",
    "\n",
    "            # Set the message and color if the desired person is not seen\n",
    "            message = 'different person'\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "            if cosine_score >= cosine_similarity_threshold:\n",
    "                # If the similarity score is above the threshold, the desired person is seen\n",
    "                message = 'same person'\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "            coords = face[:-1].astype(np.int32)\n",
    "            # Get the coordinates of the detected face\n",
    "            p1 = coords[0], coords[1]  # Top-left corner of the face rectangle\n",
    "            p2 = (coords[0] + coords[2], coords[1] + coords[3])  # Bottom-right corner of the face rectangle\n",
    "\n",
    "            # Draw a rectangle around the detected face\n",
    "            cv.rectangle(frame, p1, p2, color, 3)\n",
    "\n",
    "            # Put the message text on the frame\n",
    "            cv.putText(frame, message, (coords[0], coords[1] - 5), cv.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "            # Uncomment to display cosine score\n",
    "            # cv.putText(frame, str(cosine_score), (coords[0], coords[1] - 20), cv.FONT_HERSHEY_COMPLEX, 0.5, color, 2)\n",
    "    else:\n",
    "        # If no faces are detected, put the message text on the frame\n",
    "        cv.putText(frame, message, (30, 30), cv.FONT_HERSHEY_COMPLEX, 1, color, 2)\n",
    "\n",
    "    # Display the frame with the drawn overlays\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) & 0xff == ord('q'):\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cv.destroyAllWindows()\n",
    "webcam.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
